# MinerU Silent Failure Troubleshooting

## Problem Summary

MinerU silently fails on ~47% of PDFs without raising exceptions. The wrapper script (`process_pdfs_mineru.py`) marked these as "completed" because `PDFExtractor.extract()` returned without error, but no output files were generated.

**Discovery Date:** 2025-01-06

## Observed Symptoms

### Processing Time Correlation

| Chunk Type | Time per PDF | Output | Interpretation |
|------------|--------------|--------|----------------|
| Failed | 10-46 sec | None | Container startup only, no actual MinerU processing |
| Success | 200-600 sec (K80) | Files exist | Full MinerU pipeline execution |

**Key Indicator:** Processing time <50 seconds strongly suggests silent failure.

### Statistics

| Metric | Value |
|--------|-------|
| Result CSVs marked "completed" | 253,443 |
| Actual output directories | 134,688 |
| Missing (silent failures) | 172,631 (~68% of "completed") |
| Overlap (completed AND have output) | 80,812 |
| Have output but NOT in CSVs | 53,876 |

### Example Failed PDF

```
PMID: 12657658
PDF: /data/NIMH_scratch/adamt/osm/datalad-osm/pdfs/126/12657658.pdf
Size: 312 KB
Type: PDF document, version 1.4
Processing Time: 21.5 seconds
Output: None (directory doesn't exist)
pdftotext: Works (text is extractable)
```

## Bug Fixes Applied

### 1. False "completed" Status (Fixed)

**Before:** Script set `status = "completed"` unconditionally after `extractor.extract()` returned.

**After:** Script now verifies `{pmid}_content_list.json` exists before marking success:
```python
if json_path.exists():
    result["status"] = "completed"
else:
    result["status"] = "failed"
    result["error_msg"] = "No output files generated by MinerU"
```

### 2. Empty Directory Cleanup (Fixed)

Script now removes empty output directories on failure to prevent inode waste.

### 3. Double-Nested Directories (Fixed)

**Before:** `{prefix}/{pmid}/{pmid}/auto/`
**After:** `{prefix}/{pmid}/auto/`

## Root Cause: P100 GPU Incompatibility (Confirmed)

**Analysis Date:** 2025-01-07

### GPU Compatibility Test Results

All 5 GPU types were tested with `scripts/test_gpu_compatibility.sh`:

| GPU Type | Compute Cap | CUDA Available | MinerU Works | Processing Time | Notes |
|----------|-------------|----------------|--------------|-----------------|-------|
| K80 | 3.7 | No | **YES** | ~3.5 min | CPU fallback mode |
| P100 | 6.0 | No (unsupported) | **NO** | ~30s | Silent failure |
| V100 | 7.0 | Yes | **YES** | ~1 min | GPU mode |
| V100x | 7.0 | Yes | **YES** | ~1 min | GPU mode |
| A100 | 8.0 | Yes | **YES** | ~51s | GPU mode |

### Root Cause

The container's PyTorch 2.9.1+cu128 only supports compute capability 7.0+:

```
Tesla P100-PCIE-16GB with CUDA capability sm_60 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.
```

- **P100 (compute cap 6.0):** CUDA initialization fails silently, MinerU returns without processing
- **K80 (compute cap 3.7):** CUDA unavailable, but MinerU falls back to CPU mode and works
- **V100/V100x/A100 (compute cap 7.0+):** Full GPU acceleration works

### Node Prefix Correlation (Original Analysis)

| Node Prefix | GPU Type | Chunks | Completed | Actual Output | Silent Fail | Fail Rate | Avg Time |
|-------------|----------|--------|-----------|---------------|-------------|-----------|----------|
| cn23xx | **P100** | 393 | 10,553 | 0 | 10,553 | **100.0%** | **13.7s** |
| cn30xx | K80 | 141 | 3,667 | 3,658 | 9 | 0.2% | 203.5s |
| cn41xx | K80 | 16 | 458 | 458 | 0 | 0.0% | 190.8s |
| cn42xx | K80 | 37 | 1,062 | 1,060 | 2 | 0.2% | 191.2s |

**Key Insight:** The cn23xx nodes that showed 100% failure are P100 nodes.

### Recommended Actions

1. **Re-run failed PDFs on working GPU types only:**
   ```bash
   # Use V100 for speed (recommended)
   swarm -f mineru_retry.swarm \
       --partition gpu --gres=gpu:v100:1 \
       -g 64 -t 16 --time 04:00:00 \
       --logdir /data/adamt/osm/datafiles/mineru_logs/retry_$(date +%Y%m%d_%H%M%S)

   # Or K80 for availability (slower but works via CPU fallback)
   swarm -f mineru_retry.swarm \
       --partition gpu --gres=gpu:k80:1 \
       -g 64 -t 16 --time 08:00:00 \
       --logdir /data/adamt/osm/datafiles/mineru_logs/retry_$(date +%Y%m%d_%H%M%S)
   ```

2. **DO NOT use P100:**
   ```bash
   # This will silently fail:
   # --gres=gpu:p100:1  # BROKEN - compute cap 6.0 unsupported
   ```

3. **Optional: Rebuild container for P100 support** if P100 availability is needed:
   - Use PyTorch with CUDA 11.x that supports compute capability 6.0+
   - Current container uses PyTorch 2.9.1+cu128 which dropped sm_60 support

## Original Root Cause Hypotheses

### 1. GPU Initialization Failure (Likely - Needs Verification)

MinerU fails to initialize CUDA/GPU on certain nodes without raising an exception. The 10-46 second processing time matches container startup overhead.

**Evidence:**
- Chunk 00010 ran on cn2355 (cn23xx node)
- All 40 PDFs in that chunk failed with 10-46 sec times
- No CUDA errors in stderr
- All cn23xx chunks in available logs have 100% failure rate

**Status:** Strongly correlated with cn23xx nodes. Need to verify GPU type mapping and test all 5 GPU types (k80, p100, v100, v100x, a100).

### 2. Model Loading Failure

MinerU's pipeline backend loads multiple models:
- `doclayout_yolo` (layout detection)
- `MFD/unimernet` (formula detection)
- `RapidTable/UnetTable` (table recognition)
- `PP-OCRv5` (OCR)

If any model fails to load, the pipeline may silently skip processing.

**Investigation:** Enable MinerU debug logging to trace model loading.

### 3. Early PDF Rejection

MinerU may detect something about the PDF (encryption, corruption, format) that causes it to skip processing without error.

**Evidence Against:** `pdftotext` works on the sample failed PDF.

**Investigation:** Test specific failed PDFs manually with verbose output.

### 4. Resource Exhaustion

GPU memory or system resources may be exhausted, causing MinerU to skip processing.

**Evidence Against:**
- Only 6GB VRAM needed, K80 has 12GB
- Same chunk processes all 40 PDFs at same speed (not progressive slowdown)

## GitHub Issues Referenced

- [Issue #4139](https://github.com/opendatalab/MinerU/issues/4139): Empty output with VLLM backend (different backend, but similar pattern)
- [Issue #2481](https://github.com/opendatalab/MinerU/issues/2481): Text loss during parsing

## Investigation Plan

### Step 1: GPU Type Correlation Analysis

Parse job logs to extract:
- Node name (indicates GPU type: cn2xxx=A100, cn3xxx=V100, cn4xxx=K80)
- Processing times per PDF
- Success/failure status

```bash
# Extract node and chunk info from logs
for log in /data/adamt/osm/datafiles/mineru_logs/small/swarm_8644416_*.o; do
    chunk=$(basename $log | sed 's/swarm_8644416_\([0-9]*\).o/\1/')
    node=$(grep -m1 'cn[0-9]*' $log 2>/dev/null | head -1)
    times=$(grep '✓\|✗' $log | awk '{print $NF}' | tr -d '()s')
    echo "$chunk,$node,$times"
done
```

### Step 2: Manual Testing with Debug Logging

Test a known-failing PDF with verbose output:

```bash
# Interactive GPU session
sinteractive --gres=gpu:1 --mem=64g

# Load container
module load apptainer
source /usr/local/current/singularity/app_conf/sing_binds

# Run with debug
apptainer exec --nv /data/adamt/containers/mineru.sif python3 -c "
import logging
logging.basicConfig(level=logging.DEBUG)
from mineru.pdf_extractor import PDFExtractor
extractor = PDFExtractor(
    pdf_path='/data/NIMH_scratch/adamt/osm/datalad-osm/pdfs/126/12657658.pdf',
    output_dir='/tmp/test_output'
)
extractor.extract()
"
```

### Step 3: Batch Diagnostic Run

Create a diagnostic swarm that:
1. Captures GPU info (`nvidia-smi`)
2. Logs MinerU model loading
3. Tests a sample of known-failing PDFs
4. Reports detailed timing breakdowns

## Data Files

- **Missing PMIDs:** `/tmp/missing_pmids.txt` (172,631 PMIDs marked completed but no output)
- **Existing PMIDs:** `/tmp/existing_pmids.txt` (134,688 PMIDs with actual output)
- **Completed PMIDs:** `/tmp/completed_pmids.txt` (253,443 PMIDs marked completed in CSVs)

## Next Steps

1. [x] Analyze GPU type correlation with failure rate - **DONE: cn23xx = 100% failure, cn30xx/cn4xxx = ~0.2% failure**
2. [x] **Test all 5 GPU types** (k80, p100, v100, v100x, a100) with test_gpu_compatibility.sh - **DONE 2025-01-07**
3. [x] Identify which GPU types work and which fail - **DONE: P100 fails, K80/V100/V100x/A100 work**
4. [ ] Re-run failed PDFs on working GPU types only (exclude P100)
5. [ ] Consider rebuilding container with CUDA 11.x for P100 support if needed
6. [ ] Report issue to MinerU GitHub with GPU compatibility findings
